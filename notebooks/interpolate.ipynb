{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import savemat\n",
    "from tqdm import trange\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "import config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "  __getattr__ = dict.get\n",
    "  __setattr__ = dict.__setitem__\n",
    "  __delattr__ = dict.__delitem__\n",
    "  \n",
    "args = dotdict()\n",
    "args.data_dir = '' # set these guys accordingly\n",
    "args.exp_dir = '' # \n",
    "args.device = 'cuda'\n",
    "args.dataset = 'celebA'\n",
    "args.red_rate = 0.0\n",
    "args.test_split = 0.2\n",
    "args.validation_split = 0.0\n",
    "args.d_latent = 128\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  args.device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = config.load_dataset(args)\n",
    "\n",
    "enc, dec = config.load_model(args)\n",
    "enc.eval(); dec.eval()\n",
    "\n",
    "print ('loading pretrained auto-encoder checkpoint')\n",
    "ckpt_file = os.path.join(args.exp_dir, 'model.ckpt')\n",
    "if args.device == 'cpu':\n",
    "  ckpt = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
    "else:\n",
    "  ckpt = torch.load(ckpt_file)\n",
    "\n",
    "enc_ckpt = collections.OrderedDict()\n",
    "for k, v in ckpt['encoder'].items():\n",
    "  enc_ckpt[k.replace('module.', '')] = v\n",
    "enc.load_state_dict(enc_ckpt)\n",
    "\n",
    "dec_ckpt = collections.OrderedDict()\n",
    "for k, v in ckpt['decoder'].items():\n",
    "  dec_ckpt[k.replace('module.', '')] = v\n",
    "dec.load_state_dict(dec_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = 64\n",
    "for _setname, _set in zip(['train', 'test'], \\\n",
    "                          [train_set, test_set]):\n",
    "  print ('generating samples for {} set'.format(_setname))\n",
    "\n",
    "  inds = np.random.choice(len(_set), n_compare)\n",
    "  x_comb = []\n",
    "  for i in inds:\n",
    "    x_comb.append(_set[i].unsqueeze(0))\n",
    "    x_comb.append(\n",
    "      dec(\n",
    "        enc(x_comb[-1].to(args.device))\n",
    "      ).detach().to('cpu'))\n",
    "\n",
    "  save_image(\n",
    "    torch.cat(x_comb, 0), \n",
    "    os.path.join(args.exp_dir, 'x_vs_xrec_{}.png'.format(_setname)),\n",
    "    16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "\n",
    "for _ in range(5):\n",
    "  source_idx, target_idx = np.random.choice(len(test_set), 2)\n",
    "  x_source = test_set[source_idx].unsqueeze(0).detach().to(args.device)\n",
    "  x_target = test_set[target_idx].unsqueeze(0).detach().to(args.device)\n",
    "\n",
    "  z_source = enc(x_source)\n",
    "  z_target = enc(x_target)\n",
    "  xrec_source = dec(z_source)\n",
    "  xrec_target = dec(z_target)\n",
    "\n",
    "  z_diff = z_target - z_source\n",
    "  z_step = z_diff / n_steps\n",
    "  x_diff =  x_target - x_source\n",
    "  x_step = x_diff / n_steps\n",
    "\n",
    "  x_interp = [x_source + x_step * i for i in range(n_steps)]\n",
    "  xrec_interp = [dec(z_source + z_step * i) for i in range(n_steps)]\n",
    "  save_image(torch.cat(x_interp).to('cpu'), os.path.join(args.exp_dir, 'x_interp_{}-{}.png'.format(source_idx, target_idx)), n_steps)\n",
    "  save_image(torch.cat(xrec_interp).to('cpu'), os.path.join(args.exp_dir, 'xrec_interp_{}-{}.png'.format(source_idx, target_idx)), n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_idx in np.random.choice(len(test_set), 10):\n",
    "  x_source = test_set[source_idx].unsqueeze(0).detach().to(args.device)\n",
    "  z_source = enc(x_source)\n",
    "  n_step = 14\n",
    "  xrec_targets = []\n",
    "\n",
    "  for dim in trange(128):\n",
    "    dim_step = 0.2 # z_std[dim].to(args.device) / n_step\n",
    "\n",
    "    for step in range(n_step // 2, -1, -1):\n",
    "      z_target = z_source.clone()\n",
    "      z_target[0, dim] -= dim_step * step\n",
    "      xrec_targets.append(dec(z_target).detach().to('cpu'))\n",
    "\n",
    "    for step in range(n_step // 2):\n",
    "      z_target = z_source.clone()\n",
    "      z_target[0, dim] += dim_step * step\n",
    "      xrec_targets.append(dec(z_target).detach().to('cpu'))\n",
    "\n",
    "  save_image(\n",
    "    torch.cat(xrec_targets).to('cpu'), \n",
    "    os.path.join(args.exp_dir, 'xrec_dim-interp_{}.png'.format(source_idx)), \n",
    "    n_step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
